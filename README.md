Run `python train.py` to start training. In terminal, run `tensorboard --logdir=./runs/` to track your agent's progress

CartPole-v1  
<a href="url"><img src="https://firebasestorage.googleapis.com/v0/b/firescript-577a2.appspot.com/o/imgs%2Fapp%2FNoa%2FH-2VrmHNXz.png?alt=media&token=4c83978f-7ca0-4e2c-bec6-95e21c6377ad" height="192" ></a>  

Todo:  
* Upgrade and adjust PPO to solve all classic control and Box2D [OpenAI Gym](https://gym.openai.com) environments.  
* Solve Atari RAM environments.  
* Solve Atari vision environments.  
* Explain in detail how I arrived at all hyperparameter/implementation tweak decisions.  

Resources that may be helpful for you:  

[David Silver's lectures](https://www.davidsilver.uk/teaching/)  
[Proximal Policy Optimization](https://arxiv.org/pdf/1707.06347.pdf).  
[Implementation Matters in Deep Policy Gradients](https://openreview.net/pdf?id=r1etN1rtPB)  
[Stable Baselines](https://github.com/hill-a/stable-baselines)
